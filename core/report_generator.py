"""
ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±ì„ ë‹´ë‹¹í•˜ëŠ” ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬
ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ìƒì„¸í•œ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë°ì´í„° ë¶„ì„
- ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±
- ì¹´í…Œê³ ë¦¬ë³„ ì„±ëŠ¥ ë¶„ì„
- ëª¨ë¸ ê°„ ë¹„êµ ë¶„ì„
"""
import json
from typing import Dict, Any, List, Optional
from pathlib import Path
from datetime import datetime
from collections import defaultdict
from dataclasses import dataclass

from .benchmark_runner import BenchmarkExecutionResult

# config ëª¨ë“ˆ import (ìƒëŒ€/ì ˆëŒ€ import ëª¨ë‘ ì§€ì›)
try:
    from ..config.settings import RESULTS_DIRECTORY, DOCS_DIRECTORY
except ImportError:
    from config.settings import RESULTS_DIRECTORY, DOCS_DIRECTORY


@dataclass
class BenchmarkReport:
    """
    ìƒì„±ëœ ë²¤ì¹˜ë§ˆí¬ ë¦¬í¬íŠ¸ ì •ë³´ë¥¼ ë‹´ëŠ” ë°ì´í„° í´ë˜ìŠ¤
    
    Attributes:
        report_path: ë¦¬í¬íŠ¸ íŒŒì¼ ê²½ë¡œ
        report_content: ë¦¬í¬íŠ¸ ë‚´ìš© (ë§ˆí¬ë‹¤ìš´)
        generation_timestamp: ë¦¬í¬íŠ¸ ìƒì„± ì‹œê°
    """
    report_path: Path
    report_content: str
    generation_timestamp: datetime


class ReportGenerator:
    """
    ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” í´ë˜ìŠ¤
    
    ì´ í´ë˜ìŠ¤ëŠ” ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë°›ì•„ì„œ
    ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    
    def __init__(
        self,
        output_directory: Optional[Path] = None,
        docs_directory: Optional[Path] = None,
    ) -> None:
        """
        ReportGenerator ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            output_directory: ê²°ê³¼ JSON ì €ì¥ ë””ë ‰í† ë¦¬ (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
            docs_directory: ë¦¬í¬íŠ¸ ë§ˆí¬ë‹¤ìš´ ì €ì¥ ë””ë ‰í† ë¦¬ (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        """
        self.output_directory = output_directory or RESULTS_DIRECTORY
        self.docs_directory = docs_directory or DOCS_DIRECTORY
    
    def generate_kmle_report(
        self, results_data: Dict[str, Any]
    ) -> BenchmarkReport:
        """
        KMLE ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            results_data: ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
                (ì˜ˆ: {"tinyllama": BenchmarkExecutionResult, ...})
        
        Returns:
            BenchmarkReport: ìƒì„±ëœ ë¦¬í¬íŠ¸ ê°ì²´
        """
        timestamp = datetime.now()
        report_lines: List[str] = []
        
        # í—¤ë”
        report_lines.extend([
            "# KMLE 2023 ë²¤ì¹˜ë§ˆí¬ ë¹„êµ ë¦¬í¬íŠ¸\n",
            f"**ìƒì„± ì¼ì‹œ**: {timestamp.strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}\n",
            "**ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°**: kmle_2023.jsonl (314ê°œ ë¬¸ì œ)\n",
            "---\n",
        ])
        
        # ì „ì²´ ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸”
        report_lines.extend(self._generate_summary_table(results_data))
        
        # ìƒì„¸ ì„±ëŠ¥ ë¶„ì„
        report_lines.extend(self._generate_detailed_analysis(results_data))
        
        # ì„±ëŠ¥ ë¹„êµ ë¶„ì„
        if len(results_data) >= 2:
            report_lines.extend(
                self._generate_comparison_analysis(results_data)
            )
        
        # ê²°ë¡ 
        report_lines.extend(self._generate_conclusion(results_data))
        
        # í‘¸í„°
        report_lines.append("\n---\n")
        report_lines.append(
            f"**ë¦¬í¬íŠ¸ ìƒì„± ì‹œê°„**: {timestamp.strftime('%Y-%m-%d %H:%M:%S')}\n"
        )
        
        # ë¦¬í¬íŠ¸ ì €ì¥
        report_content = "".join(report_lines)
        report_filename = (
            f"KMLE_2023_BENCHMARK_REPORT_{timestamp.strftime('%Y%m%d_%H%M%S')}.md"
        )
        # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ëŠ” docs ë””ë ‰í† ë¦¬ì— ì €ì¥
        report_path = self.docs_directory / report_filename
        
        with open(report_path, "w", encoding="utf-8") as file:
            file.write(report_content)
        
        return BenchmarkReport(
            report_path=report_path,
            report_content=report_content,
            generation_timestamp=timestamp,
        )
    
    def _generate_summary_table(
        self, results_data: Dict[str, Any]
    ) -> List[str]:
        """
        ì „ì²´ ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸”ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            results_data: ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë°ì´í„°
        
        Returns:
            List[str]: ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” ë¼ì¸ ë¦¬ìŠ¤íŠ¸
        """
        lines = [
            "## ğŸ“Š ì „ì²´ ì„±ëŠ¥ ë¹„êµ\n",
            "| ëª¨ë¸ | ì •í™•ë„ | í‰ê·  ìƒì„± ì‹œê°„ | ì´ ì†Œìš” ì‹œê°„ | ì´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ |\n",
            "|------|--------|---------------|-------------|-----------------|\n",
        ]
        
        for model_key in ["tinyllama", "deepseek"]:
            if model_key in results_data:
                result = results_data[model_key]
                total_memory = sum(result.get("memory_usage", {}).values())
                lines.append(
                    f"| {result.get('model_type', 'N/A')} | "
                    f"{result.get('accuracy', 0):.2f}% "
                    f"({result.get('correct_answers', 0)}/{result.get('total_questions', 0)}) | "
                    f"{result.get('avg_generation_time', 0):.2f}ì´ˆ | "
                    f"{result.get('total_time', 0)/60:.1f}ë¶„ | "
                    f"{total_memory:.2f} GB |\n"
                )
        
        lines.append("\n---\n")
        return lines
    
    def _generate_detailed_analysis(
        self, results_data: Dict[str, Any]
    ) -> List[str]:
        """
        ìƒì„¸ ì„±ëŠ¥ ë¶„ì„ ì„¹ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            results_data: ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë°ì´í„°
        
        Returns:
            List[str]: ë§ˆí¬ë‹¤ìš´ ë¼ì¸ ë¦¬ìŠ¤íŠ¸
        """
        lines = ["## ğŸ” ìƒì„¸ ì„±ëŠ¥ ë¶„ì„\n"]
        
        for model_key in ["tinyllama", "deepseek"]:
            if model_key not in results_data:
                continue
            
            result = results_data[model_key]
            lines.extend([
                f"### {result.get('model_type', 'N/A')}\n\n",
                f"- **ëª¨ë¸ ì´ë¦„**: {result.get('model_name', 'N/A')}\n",
                f"- **ì–‘ìí™” ì‚¬ìš©**: "
                f"{'ì˜ˆ (4-bit)' if result.get('use_quantization', False) else 'ì•„ë‹ˆì˜¤'}\n",
                f"- **ì „ì²´ ì •í™•ë„**: "
                f"{result.get('accuracy', 0):.2f}% "
                f"({result.get('correct_answers', 0)}/{result.get('total_questions', 0)})\n",
                f"- **í‰ê·  ìƒì„± ì‹œê°„**: "
                f"{result.get('avg_generation_time', 0):.2f}ì´ˆ\n",
                f"- **ì´ ì†Œìš” ì‹œê°„**: "
                f"{result.get('total_time', 0)/60:.1f}ë¶„ "
                f"({result.get('total_time', 0):.0f}ì´ˆ)\n",
            ])
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
            lines.append("- **GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**:\n")
            total_memory = 0.0
            for gpu_idx, memory in sorted(
                result.get("memory_usage", {}).items()
            ):
                lines.append(f"  - GPU {gpu_idx}: {memory:.2f} GB\n")
                total_memory += memory
            lines.append(f"  - **ì´í•©**: {total_memory:.2f} GB\n")
            
            # ì¹´í…Œê³ ë¦¬ë³„ ì •í™•ë„
            category_stats = self._calculate_category_statistics(
                result.get("results", [])
            )
            if category_stats:
                lines.extend([
                    "- **ì¹´í…Œê³ ë¦¬ë³„ ì •í™•ë„**:\n",
                    "  | ì¹´í…Œê³ ë¦¬ | ì •í™•ë„ | ì •ë‹µ/ì „ì²´ |\n",
                    "  |---------|--------|----------|\n",
                ])
                for category, stats in sorted(category_stats.items()):
                    accuracy = (
                        (stats["correct"] / stats["total"]) * 100.0
                        if stats["total"] > 0
                        else 0.0
                    )
                    lines.append(
                        f"  | {category} | {accuracy:.1f}% | "
                        f"{stats['correct']}/{stats['total']} |\n"
                    )
            
            lines.append("\n")
        
        return lines
    
    def _calculate_category_statistics(
        self, individual_results: List[Dict[str, Any]]
    ) -> Dict[str, Dict[str, int]]:
        """
        ì¹´í…Œê³ ë¦¬ë³„ í†µê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        Args:
            individual_results: ê°œë³„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            Dict[str, Dict[str, int]]: ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
        """
        category_stats: Dict[str, Dict[str, int]] = defaultdict(
            lambda: {"correct": 0, "total": 0}
        )
        
        for result in individual_results:
            category = result.get("category", "N/A")
            category_stats[category]["total"] += 1
            if result.get("is_correct", False):
                category_stats[category]["correct"] += 1
        
        return dict(category_stats)
    
    def _generate_comparison_analysis(
        self, results_data: Dict[str, Any]
    ) -> List[str]:
        """
        ëª¨ë¸ ê°„ ë¹„êµ ë¶„ì„ ì„¹ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            results_data: ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë°ì´í„°
        
        Returns:
            List[str]: ë§ˆí¬ë‹¤ìš´ ë¼ì¸ ë¦¬ìŠ¤íŠ¸
        """
        if "tinyllama" not in results_data or "deepseek" not in results_data:
            return []
        
        tiny = results_data["tinyllama"]
        deepseek = results_data["deepseek"]
        
        lines = ["## ğŸ“ˆ ì„±ëŠ¥ ë¹„êµ ë¶„ì„\n"]
        
        # ì •í™•ë„ ë¹„êµ
        acc_diff = deepseek.get("accuracy", 0) - tiny.get("accuracy", 0)
        lines.extend([
            "### ì •í™•ë„\n",
            f"- **DeepSeek R1 70B**: {deepseek.get('accuracy', 0):.2f}%\n",
            f"- **TinyLlama**: {tiny.get('accuracy', 0):.2f}%\n",
            f"- **ì°¨ì´**: {acc_diff:+.2f}%p\n\n",
        ])
        
        # ì†ë„ ë¹„êµ
        tiny_time = tiny.get("avg_generation_time", 0)
        deepseek_time = deepseek.get("avg_generation_time", 0)
        speed_ratio = (
            tiny_time / deepseek_time if deepseek_time > 0 else 0.0
        )
        lines.extend([
            "### ìƒì„± ì†ë„\n",
            f"- **DeepSeek R1 70B**: {deepseek_time:.2f}ì´ˆ/ë¬¸ì œ\n",
            f"- **TinyLlama**: {tiny_time:.2f}ì´ˆ/ë¬¸ì œ\n",
        ])
        if speed_ratio > 0:
            lines.append(f"- **TinyLlamaê°€ {speed_ratio:.1f}ë°° ë¹ ë¦„**\n\n")
        
        # ë©”ëª¨ë¦¬ ë¹„êµ
        tiny_memory = sum(tiny.get("memory_usage", {}).values())
        deepseek_memory = sum(deepseek.get("memory_usage", {}).values())
        memory_ratio = (
            deepseek_memory / tiny_memory if tiny_memory > 0 else 0.0
        )
        lines.extend([
            "### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰\n",
            f"- **DeepSeek R1 70B**: {deepseek_memory:.2f} GB\n",
            f"- **TinyLlama**: {tiny_memory:.2f} GB\n",
        ])
        if memory_ratio > 0:
            lines.append(
                f"- **DeepSeekì´ {memory_ratio:.1f}ë°° ë” ë§ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©**\n\n"
            )
        
        return lines
    
    def _generate_conclusion(
        self, results_data: Dict[str, Any]
    ) -> List[str]:
        """
        ê²°ë¡  ì„¹ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            results_data: ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë°ì´í„°
        
        Returns:
            List[str]: ë§ˆí¬ë‹¤ìš´ ë¼ì¸ ë¦¬ìŠ¤íŠ¸
        """
        lines = ["## ğŸ’¡ ê²°ë¡ \n"]
        
        if "tinyllama" in results_data and "deepseek" in results_data:
            tiny = results_data["tinyllama"]
            deepseek = results_data["deepseek"]
            
            lines.append("### ì£¼ìš” ë°œê²¬ì‚¬í•­\n\n")
            
            # ì •í™•ë„ ë¹„êµ
            acc_diff = deepseek.get("accuracy", 0) - tiny.get("accuracy", 0)
            if acc_diff > 0:
                lines.append(
                    f"1. **ì •í™•ë„**: DeepSeek R1 70Bê°€ TinyLlamaë³´ë‹¤ "
                    f"{acc_diff:.2f}%p ë†’ì€ ì •í™•ë„ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.\n"
                )
            else:
                lines.append(
                    f"1. **ì •í™•ë„**: TinyLlamaê°€ DeepSeek R1 70Bë³´ë‹¤ "
                    f"{abs(acc_diff):.2f}%p ë†’ì€ ì •í™•ë„ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.\n"
                )
            
            # ì†ë„ ë¹„êµ
            tiny_time = tiny.get("avg_generation_time", 0)
            deepseek_time = deepseek.get("avg_generation_time", 0)
            if tiny_time < deepseek_time:
                speed_ratio = deepseek_time / tiny_time if tiny_time > 0 else 0
                lines.append(
                    f"2. **ì†ë„**: TinyLlamaê°€ DeepSeek R1 70Bë³´ë‹¤ ì•½ "
                    f"{speed_ratio:.1f}ë°° ë¹ ë¥´ê²Œ ìƒì„±í–ˆìŠµë‹ˆë‹¤.\n"
                )
            else:
                speed_ratio = tiny_time / deepseek_time if deepseek_time > 0 else 0
                lines.append(
                    f"2. **ì†ë„**: DeepSeek R1 70Bê°€ TinyLlamaë³´ë‹¤ ì•½ "
                    f"{speed_ratio:.1f}ë°° ë¹ ë¥´ê²Œ ìƒì„±í–ˆìŠµë‹ˆë‹¤.\n"
                )
            
            # ë©”ëª¨ë¦¬ ë¹„êµ
            tiny_memory = sum(tiny.get("memory_usage", {}).values())
            deepseek_memory = sum(deepseek.get("memory_usage", {}).values())
            memory_ratio = (
                deepseek_memory / tiny_memory if tiny_memory > 0 else 0.0
            )
            lines.append(
                f"3. **ë©”ëª¨ë¦¬**: DeepSeek R1 70BëŠ” TinyLlamaë³´ë‹¤ ì•½ "
                f"{memory_ratio:.1f}ë°° ë§ì€ ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.\n"
            )
            
            lines.append("\n### ê¶Œì¥ì‚¬í•­\n\n")
            if deepseek.get("accuracy", 0) > tiny.get("accuracy", 0) + 5:
                lines.append(
                    "- **ë†’ì€ ì •í™•ë„ê°€ í•„ìš”í•œ ê²½ìš°**: DeepSeek R1 70B ì‚¬ìš© ê¶Œì¥\n"
                )
            if tiny_time < deepseek_time / 2:
                lines.append(
                    "- **ë¹ ë¥¸ ì‘ë‹µì´ í•„ìš”í•œ ê²½ìš°**: TinyLlama ì‚¬ìš© ê¶Œì¥\n"
                )
            lines.append(
                "- **ë¦¬ì†ŒìŠ¤ ì œì•½ì´ ìˆëŠ” ê²½ìš°**: TinyLlama ì‚¬ìš© ê¶Œì¥ "
                "(ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì ìŒ)\n"
            )
        
        return lines

